<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://liuhanmeng.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://liuhanmeng.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-04-18T09:42:46+00:00</updated><id>https://liuhanmeng.github.io/feed.xml</id><title type="html">刘汉蒙（Hanmeng Liu）</title><subtitle>the personal website of an NLP researcher. </subtitle><entry><title type="html">大模型约束解码（Constrained decoding）与结构化输出</title><link href="https://liuhanmeng.github.io/blog/2025/structured-output/" rel="alternate" type="text/html" title="大模型约束解码（Constrained decoding）与结构化输出"/><published>2025-04-15T15:09:00+00:00</published><updated>2025-04-15T15:09:00+00:00</updated><id>https://liuhanmeng.github.io/blog/2025/structured-output</id><content type="html" xml:base="https://liuhanmeng.github.io/blog/2025/structured-output/"><![CDATA[<h1 id="背景">背景</h1> <h2 id="为什么要控制输出">为什么要控制输出</h2> <ol> <li>结构化输出内容、模板化输出（Code, HTML, DSL, JSON, SQL）</li> <li>多项选择</li> <li>长度限制</li> <li>语义约束</li> <li>风格约束</li> <li>避免幻觉</li> <li>构建智能体</li> </ol> <h1 id="openai-怎么做的">OpenAI 怎么做的</h1> <h2 id="阶段一json-mode">阶段一：JSON Mode</h2> <ul> <li>GPT-4</li> <li>提高JSON输出的可靠性</li> <li>但并不能保证有效性</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">openai</span> <span class="kn">import</span> <span class="n">OpenAI</span>
<span class="n">client</span> <span class="o">=</span> <span class="nc">OpenAI</span><span class="p">(</span><span class="n">api_key</span><span class="o">=</span><span class="sh">"</span><span class="s">EMPTY</span><span class="sh">"</span><span class="p">,</span> <span class="n">base_url</span><span class="o">=</span><span class="sh">""</span><span class="p">)</span>
<span class="n">responses</span> <span class="o">=</span> <span class="n">client</span><span class="p">.</span><span class="n">chat</span><span class="p">.</span><span class="n">completions</span><span class="p">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">model</span> <span class="o">=</span> <span class="sh">""</span><span class="p">,</span>
    <span class="n">messages</span> <span class="o">=</span> <span class="p">[{}],</span>
    <span class="n">response_format</span><span class="o">=</span><span class="p">{</span><span class="sh">"</span><span class="s">type</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">json_object</span><span class="sh">"</span><span class="p">}</span>
</code></pre></div></div> <p><strong>logit_bias</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">completion</span> <span class="o">=</span> <span class="n">client</span><span class="p">.</span><span class="n">chat</span><span class="p">.</span><span class="n">commpletions</span><span class="p">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">model</span> <span class="o">=</span> <span class="sh">""</span><span class="p">,</span>
    <span class="n">messages</span> <span class="o">=</span> <span class="p">[{}],</span>
    <span class="n">logit_bias</span> <span class="o">=</span> <span class="p">{</span><span class="mi">2435</span><span class="p">:</span><span class="o">-</span><span class="mi">100</span><span class="p">,</span> <span class="mi">640</span><span class="p">:</span><span class="o">-</span><span class="mi">100</span><span class="p">}</span>
</code></pre></div></div> <blockquote> <p>非确定性方法</p> <ol> <li>借助外部工具</li> <li>提示工程</li> <li>反复尝试</li> <li>打补丁</li> </ol> </blockquote> <h2 id="阶段二structured-output">阶段二：Structured Output</h2> <ul> <li>GPT-4o</li> <li>严格匹配用户定义的JSON schemas</li> </ul> <h3 id="如何使用">如何使用</h3> <ol> <li>Function Calling</li> <li>response_format参数</li> <li>支持Pydantic对象</li> <li>结合response_format参数</li> </ol> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">pydantic</span> <span class="kn">import</span> <span class="n">BaseModel</span>

<span class="kn">from</span> <span class="n">openai</span> <span class="kn">import</span> <span class="n">OpenAI</span>


<span class="k">class</span> <span class="nc">Step</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="n">explanation</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">output</span><span class="p">:</span> <span class="nb">str</span>


<span class="k">class</span> <span class="nc">MathResponse</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="n">steps</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Step</span><span class="p">]</span>
    <span class="n">final_answer</span><span class="p">:</span> <span class="nb">str</span>


<span class="n">client</span> <span class="o">=</span> <span class="nc">OpenAI</span><span class="p">()</span>

<span class="n">completion</span> <span class="o">=</span> <span class="n">client</span><span class="p">.</span><span class="n">beta</span><span class="p">.</span><span class="n">chat</span><span class="p">.</span><span class="n">completions</span><span class="p">.</span><span class="nf">parse</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="sh">"</span><span class="s">gpt-4o-2024-08-06</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
        <span class="p">{</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">system</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">You are a helpful math tutor.</span><span class="sh">"</span><span class="p">},</span>
        <span class="p">{</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">user</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">solve 8x + 31 = 2</span><span class="sh">"</span><span class="p">},</span>
    <span class="p">],</span>
    <span class="n">tools</span><span class="o">=</span><span class="p">[</span>
        <span class="n">openai</span><span class="p">.</span><span class="nf">pydantic_function_tool</span><span class="p">(</span><span class="n">MathResponse</span><span class="p">),</span>
    <span class="p">],</span>
    <span class="c1"># response_format=MathResponse,
</span><span class="p">)</span>

<span class="n">message</span> <span class="o">=</span> <span class="n">completion</span><span class="p">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">message</span>
<span class="k">if</span> <span class="n">message</span><span class="p">.</span><span class="n">parsed</span><span class="p">:</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">message</span><span class="p">.</span><span class="n">parsed</span><span class="p">.</span><span class="n">steps</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">message</span><span class="p">.</span><span class="n">parsed</span><span class="p">.</span><span class="n">final_answer</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">message</span><span class="p">.</span><span class="n">refusal</span><span class="p">)</span>
</code></pre></div></div> <h3 id="好处">好处</h3> <ul> <li>Dynamically generating user interfaces based on the user’s intent</li> <li>Separating a final answer from supporting reasoning or additional commentary</li> <li>Extracting structured data from unstructured data</li> </ul> <h3 id="如何实现">如何实现</h3> <ul> <li>GPT-4o 特别训练以理解复杂的schemas （non-determinstic）</li> <li>工程化方法 （deterministic）</li> </ul> <h3 id="constrained-decoding--constrained-sampling">Constrained Decoding / Constrained Sampling</h3> <p>OpenAI实现约束解码的技术路线：</p> <p>JSON schemas -&gt; CFG (context-free grammar) -&gt; 结合语法规则和已有token来确定下一步的有效token -&gt; 掩码下一步采样</p> <p>为什么使用CFG：</p> <ul> <li>Finite State Machines （FSMs）</li> <li> <p>regexes （FSMs）</p> <p>无法处理递归schemas</p> </li> </ul> <p><strong>Structured Outputs</strong> takes inspiration from excellent work from the open source community: namely, the outlines⁠(opens in a new window), jsonformer⁠(opens in a new window), instructor⁠(opens in a new window), guidance⁠(opens in a new window), and lark⁠(opens in a new window) libraries.</p> <h1 id="技术原理">技术原理</h1> <h2 id="解码技术">解码技术</h2> <p>大模型能力提升的三驾马车：</p> <ul> <li>训练微调</li> <li>提示工程</li> <li>解码策略</li> </ul> <h3 id="什么是语言模型解码">什么是语言模型解码</h3> <p><img src="https://s2.loli.net/2025/04/15/JQ8pjG9VzyZsn5d.png" alt="decoding.png"/></p> <h3 id="解码策略">解码策略</h3> <h4 id="最常用的几种解码方式">最常用的几种解码方式</h4> <p>MAP (maximum a-posteriori) decoding</p> <ul> <li>Greedy Decoding</li> <li>(narrow) beam search (multiple prefixs) 问题： degeneration: short, repeatitive sequen</li> </ul> <p>Stochastic methods</p> <ul> <li>Top-k sampling</li> <li>Top-p sampling (Nucleus sampling)</li> <li>Temperature sampling (0&lt;t&lt;1, 1, t&gt;1)</li> </ul> <h4 id="参数设置">参数设置</h4> <p>GenerationMixin</p> <p><strong>model.generate()</strong></p> <ul> <li>GenerationConfig <ul> <li>greedy decoding if num_beams=1 and do_sample=False</li> <li>contrastive search if penalty_alpha&gt;0 and top_k&gt;1</li> <li>multinomial sampling if num_beams=1 and do_sample=True</li> <li>beam-search decoding if num_beams&gt;1 and do_sample=False</li> <li>beam-search multinomial sampling if num_beams&gt;1 and do_sample=True</li> <li>diverse beam-search decoding if num_beams&gt;1 and num_beam_groups&gt;1</li> <li>constrained beam-search decoding if constraints!=None or force_words_ids!=None</li> <li>assisted decoding if assistant_model or prompt_lookup_num_tokens is passed to .generate()</li> </ul> </li> <li>logits_processor <ul> <li>LogitsProcessorList <ul> <li>minLengthLogitsProcessor</li> <li>PepetitionPenaltyLogitsProcessor</li> <li>NoRepeatNGramLogitsProccesor</li> </ul> </li> </ul> </li> <li>StoppingCriteria</li> </ul> <hr/> <p><img src="https://s2.loli.net/2025/04/15/Fo5iHONsCnQuybj.png" alt="pipeline.png"/></p> <p><strong>LogitsProcessor类</strong>是专门改变模型输出概率分布的工具</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSeq2SeqLM</span><span class="p">,</span> <span class="n">TextStreamer</span>
<span class="kn">from</span> <span class="n">transformers.generation.logits_process</span> <span class="kn">import</span> <span class="n">LogitsProcessor</span><span class="p">,</span> <span class="n">LogitsProcessorList</span>
<span class="kn">from</span> <span class="n">typing</span> <span class="kn">import</span> <span class="n">List</span>
<span class="kn">import</span> <span class="n">torch</span>

<span class="k">class</span> <span class="nc">new_logits_processor</span><span class="p">(</span><span class="n">LogitsProcessor</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">forbid_token_id_list</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">forbid_token_id_list</span> <span class="o">=</span> <span class="n">forbid_token_id_list</span>

    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">:</span> <span class="n">torch</span><span class="o">&gt;</span><span class="n">LongTensor</span><span class="p">,</span> <span class="n">scores</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">FloatTensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">FloatTensor</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">id_</span> <span class="ow">in</span> <span class="n">self</span><span class="p">,</span><span class="n">forbid_token_id_list</span><span class="p">:</span>
            <span class="n">scores</span><span class="p">{:,</span> <span class="n">id_</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="nf">float</span><span class="p">(</span><span class="sh">'</span><span class="s">inf</span><span class="sh">'</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">scores</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pip</span> <span class="n">install</span> <span class="n">torch</span>
<span class="n">pip</span> <span class="n">install</span> <span class="sh">"</span><span class="s">transformers==4.24.0</span><span class="sh">"</span>

<span class="kn">from</span> <span class="n">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">GPT2LMHeadModel</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">,</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="sh">'</span><span class="s">gpt2-large</span><span class="sh">'</span><span class="p">)</span>
<span class="n">input_ids</span> <span class="o">=</span> <span class="nf">tokenizer</span><span class="p">(</span><span class="sh">'</span><span class="s">DeepMind Company is</span><span class="sh">'</span> <span class="p">,</span> <span class="n">return_tensor</span><span class="o">=</span><span class="sh">'</span><span class="s">pt</span><span class="sh">'</span><span class="p">).</span><span class="n">input_ids</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">GPT2LMHeadModel</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="sh">'</span><span class="s">gpt2-large</span><span class="sh">'</span><span class="p">)</span>

<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">generate</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">.</span><span class="nf">decode</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">impoprt</span> <span class="n">torch</span>
<span class="n">form</span> <span class="n">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">GPT2LMHeadModel</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="sh">'</span><span class="s">gpt2-large</span><span class="sh">'</span><span class="p">}</span>
<span class="n">input_ids</span> <span class="o">=</span> <span class="nf">tokenizer</span><span class="p">(</span><span class="sh">'</span><span class="s">DeepMind company is</span><span class="sh">'</span><span class="p">,</span> <span class="n">return_tensor</span><span class="o">=</span><span class="sh">'</span><span class="s">pt</span><span class="sh">'</span><span class="p">).</span><span class="n">input_ids</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">GPT2LMHeadModel</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="sh">'</span><span class="s">gpt2-large</span><span class="sh">'</span><span class="p">)</span>

<span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="mf">0.</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">generate</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">do_sample</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">top_p</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">.</span><span class="nf">decode</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
</code></pre></div></div> <p>更高阶的解码方法</p> <ul> <li>Contrastive decoding / Contrastive search</li> <li>Speculative Sampling / assisted decoding</li> <li>DoLA</li> </ul> <p>Contrastive Search <img src="https://s2.loli.net/2025/04/15/CYOHRUkJp4aNtKm.png" alt="formulation.png"/></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Contrastive decoding
</span><span class="kn">from</span> <span class="n">transformers</span> <span class="kn">import</span> <span class="n">GPT2Tokenizer</span><span class="p">,</span> <span class="n">GPT2LMHeadModel</span>

<span class="n">model_name</span> <span class="o">=</span> <span class="sh">'</span><span class="s">gpt2-large</span><span class="sh">'</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">GPT2Tokenizer</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">GPT2LMHeadModel</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">pad_token_id</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">eos_token_id</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>

<span class="n">input_ids</span> <span class="o">=</span> <span class="nf">tokenizer</span><span class="p">(</span><span class="sh">'</span><span class="s">DeepMind company is</span><span class="sh">'</span><span class="p">,</span> <span class="n">return_tensor</span><span class="o">=</span><span class="sh">'</span><span class="s">pt</span><span class="sh">'</span><span class="p">).</span><span class="n">input_ids</span>

<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">generate</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">penalty_alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">512</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">.</span><span class="nf">decode</span><span class="p">(</span><span class="n">outputp</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># assisted decoding
</span><span class="kn">from</span> <span class="n">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoTokenizer</span>

<span class="n">prompt</span> <span class="o">=</span> <span class="sh">"</span><span class="s">Alice and Bob</span><span class="sh">"</span>
<span class="n">checkpoint</span> <span class="o">=</span> <span class="sh">"</span><span class="s">google/gemma-2-9b</span><span class="sh">"</span>
<span class="n">assistant_checkpoint</span> <span class="o">=</span> <span class="sh">"</span><span class="s">double7/vicuna-68m</span><span class="sh">"</span>

<span class="n">assistant_tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="n">assistant_checkpoint</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="nf">tokenizer</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="sh">"</span><span class="s">pt</span><span class="sh">"</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>
<span class="n">assistant_model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="n">assistant_checkpoint</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">generate</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">,</span> <span class="n">assistant_model</span><span class="o">=</span><span class="n">assistant_model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">assistant_tokenizer</span><span class="o">=</span><span class="n">assistant_tokenizer</span><span class="p">)</span>
<span class="n">tokenizer</span><span class="p">.</span><span class="nf">batch_decode</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">set_seed</span>
<span class="kn">import</span> <span class="n">torch</span>
<span class="kn">from</span> <span class="n">accelerate.test_utils.testing</span> <span class="kn">import</span> <span class="n">get_backend</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="sh">"</span><span class="s">huggyllama/llama-7b</span><span class="sh">"</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="sh">"</span><span class="s">huggyllama/llama-7b</span><span class="sh">"</span><span class="p">,</span> <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float16</span><span class="p">)</span>
<span class="n">device</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="nf">get_backend</span><span class="p">()</span> <span class="c1"># automatically detects the underlying device type (CUDA, CPU, XPU, MPS, etc.)
</span><span class="n">model</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="nf">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">text</span> <span class="o">=</span> <span class="sh">"</span><span class="s">On what date was the Declaration of Independence officially signed?</span><span class="sh">"</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="nf">tokenizer</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="sh">"</span><span class="s">pt</span><span class="sh">"</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># vanilla greddy decoding
</span><span class="n">vanilla_output</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">generate</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">,</span> <span class="n">do_sample</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
<span class="n">tokenizer</span><span class="p">.</span><span class="nf">batch_decode</span><span class="p">(</span><span class="n">vanilla_output</span><span class="p">[:,</span> <span class="n">inputs</span><span class="p">.</span><span class="n">input_ids</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]:],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="p">[</span><span class="sh">'</span><span class="se">\n</span><span class="s">The Declaration of Independence was signed on July 4, 1776.</span><span class="se">\n</span><span class="s">What was the date of the signing of the Declaration of Independence?</span><span class="se">\n</span><span class="s">The Declaration of Independence was signed on July 4,</span><span class="sh">'</span><span class="p">]</span>

<span class="c1">#DoLa decoding with contrasting higher part of layers
</span><span class="n">dola_high_output</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">generate</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">,</span> <span class="n">do_sample</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">dola_layers</span><span class="o">=</span><span class="sh">'</span><span class="s">high</span><span class="sh">'</span><span class="p">)</span>
<span class="n">tokenizer</span><span class="p">.</span><span class="nf">batch_decode</span><span class="p">(</span><span class="n">dola_high_output</span><span class="p">[:,</span> <span class="n">inputs</span><span class="p">.</span><span class="n">input_ids</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]:],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="p">[</span><span class="sh">'</span><span class="se">\n</span><span class="s">July 4, 1776, when the Continental Congress voted to separate from Great Britain. The 56 delegates to the Continental Congress signed the Declaration on August 2, 1776.</span><span class="sh">'</span><span class="p">]</span>

<span class="c1"># DoLa decoding with contrasting specific layers
</span><span class="n">dola_custom_output</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">generate</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">,</span> <span class="n">do_sample</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">dola_layers</span><span class="o">=</span><span class="p">[</span><span class="mi">28</span><span class="p">,</span><span class="mi">30</span><span class="p">],</span> <span class="n">repetition_penalty</span><span class="o">=</span><span class="mf">1.2</span><span class="p">)</span>
<span class="n">tokenizer</span><span class="p">.</span><span class="nf">batch_decode</span><span class="p">(</span><span class="n">dola_custom_output</span><span class="p">[:,</span> <span class="n">inputs</span><span class="p">.</span><span class="n">input_ids</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]:],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="p">[</span><span class="sh">'</span><span class="se">\n</span><span class="s">It was officially signed on 2 August 1776, when 56 members of the Second Continental Congress, representing the original 13 American colonies, voted unanimously for the resolution for independence. The 2</span><span class="sh">'</span><span class="p">]</span>
</code></pre></div></div> <h3 id="当前工作流">当前工作流</h3> <p>以OpenAI client为例</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">openai</span> <span class="kn">import</span> <span class="n">OpenAI</span>

<span class="c1"># initialize the client but point it to TGI
</span><span class="n">client</span> <span class="o">=</span> <span class="nc">OpenAI</span><span class="p">(</span>
    <span class="n">base_url</span> <span class="o">=</span> <span class="sh">"</span><span class="s">&lt;ENDPOINT_URL&gt;</span><span class="sh">"</span> <span class="o">+</span> <span class="sh">"</span><span class="s">/v1/</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">api_key</span> <span class="o">=</span> <span class="sh">"</span><span class="s">&lt;HF_API_TOKEN&gt;</span><span class="sh">"</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">messages</span> <span class="o">=</span> <span class="p">[{</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">user</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="n">prompt</span><span class="p">}]</span>
<span class="n">chat_comopletion</span> <span class="o">=</span> <span class="n">client</span><span class="p">.</span><span class="n">chat</span><span class="p">.</span><span class="n">completions</span><span class="p">.</span><span class="nf">create</span><span class="p">(</span>
    <span class="n">model</span> <span class="o">=</span> <span class="sh">""</span><span class="p">,</span>
    <span class="n">messages</span> <span class="o">=</span> <span class="n">messages</span><span class="p">,</span> 
    <span class="n">stream</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span>
    <span class="n">max_tokens</span> <span class="o">=</span> <span class="mi">1024</span>
<span class="p">)</span>
<span class="n">message</span> <span class="o">=</span> <span class="n">chat_completion</span><span class="p">.</span><span class="n">choice</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">message</span><span class="p">.</span><span class="n">content</span>
</code></pre></div></div> <p>支持的参数：</p> <ul> <li>stream</li> <li>max_tokens</li> <li>frequency_penalty</li> <li>logprobs</li> <li>seed</li> <li>temperature</li> <li> <p>top_p</p> <p>以上都是token-level的生成算法</p> </li> </ul> <h3 id="搜索方法-openai-o1">搜索方法 (OpenAI o1)</h3> <p><img src="https://s2.loli.net/2025/04/15/tsZhR7nFMyWXD26.png" alt="search.png"/></p> <ul> <li>多模型多提示组合</li> <li>问题分解</li> <li>并行解码 （自我一致性，多数投票，重排序，概率分布转移）</li> <li>TOT，GOT，MCTS</li> </ul> <p>o3</p> <ul> <li>“program synthesis” for task adaptation</li> <li>natural language program search</li> <li>evaluator model: a new kind of reasoning</li> <li>executing its own programs</li> <li>deep learning guided program search</li> </ul> <h2 id="constrained-decoding">Constrained Decoding</h2> <h3 id="开源工作">开源工作</h3> <table> <thead> <tr> <th>Library</th> <th>Feature</th> </tr> </thead> <tbody> <tr> <td>ggerganov/llama.cpp</td> <td>contains a built-in support for CFG and supports JSON Schema through conversion to CFG</td> </tr> <tr> <td>guidance-ai/guidance</td> <td>CFG, Regex, JSON Schema, Token Forcing, compatible with Transformers, LLAMA-CPP</td> </tr> <tr> <td>outlines-dev/outlines</td> <td>CFG, Unicode support, Hugging Face ecosystem, VLLM support</td> </tr> <tr> <td>sgl-project/sglang</td> <td>Regex support, emphasis on LLM inference efficiency, compressed FSM</td> </tr> <tr> <td>eth-sri/lmql</td> <td>Regex support, various constraints, more powerful control flow</td> </tr> <tr> <td>jxnl/instructor</td> <td>Try-Reject-Repeat approach to ensure constraints are met</td> </tr> <tr> <td>microsoft/aici</td> <td>A general framework of LLM controller with native support for CFG, Regex, JSON Schema</td> </tr> <tr> <td>noamgat/lm-format-enforcer</td> <td>Regex, JSON Schema, Beam Search etc.</td> </tr> <tr> <td>mlc-ai/xgrammar</td> <td>CFG, careful system optimizations</td> </tr> <tr> <td>epfl-dlab/transformers-CFG</td> <td>CFG (EBNF Interface), Compatible with Transformers, Easy to extend for research</td> </tr> <tr> <td>uiuc-focal-lab/syncode</td> <td>CFG generation that supports builtin grammars like JSON, Python, Go, and more</td> </tr> <tr> <td>r2d4/parserllm</td> <td>Use context-free grammars with an LLM</td> </tr> </tbody> </table> <h2 id="应用">应用</h2> <ul> <li>有效的json格式</li> <li>遵循正则表达式</li> <li>遵循CFG语法</li> <li>复杂提示，搜索</li> </ul> <h3 id="案例">案例</h3> <ul> <li>Knowledge Graph Generation</li> <li>ReAct Agent</li> <li>Extract data to CSV</li> <li></li> </ul> <h3 id="案例一使用有限状态机限制模型输出浮点数">案例一：使用有限状态机限制模型输出浮点数</h3> <p><img src="https://s2.loli.net/2025/04/15/c4WJMOeoFl8XYxb.png" alt="fsm.png"/></p> <h3 id="案例二多项选择">案例二：多项选择</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">outlines</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">outlines</span><span class="p">.</span><span class="n">models</span><span class="p">.</span><span class="nf">transformers</span><span class="p">(</span><span class="sh">"</span><span class="s">microsoft/Phi-3-mini-4k-instruct</span><span class="sh">"</span><span class="p">)</span>

<span class="n">prompt</span> <span class="o">=</span> <span class="sh">"""</span><span class="s">You are a sentiment-labelling assistant.
Is the following review positive or negative?

Review: This restaurant is just awesome!
</span><span class="sh">"""</span>

<span class="n">generator</span> <span class="o">=</span> <span class="n">outlines</span><span class="p">.</span><span class="n">generate</span><span class="p">.</span><span class="nf">choice</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">[</span><span class="sh">"</span><span class="s">Positive</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Negative</span><span class="sh">"</span><span class="p">])</span>
<span class="n">answer</span> <span class="o">=</span> <span class="nf">generator</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>
</code></pre></div></div> <h3 id="案例三sql生成">案例三：SQL生成</h3> <p><a href="https://github.com/zbrookle/sql_to_ibis/blob/main/sql_to_ibis/grammar/sql.lark">语法文件</a></p> <p>预期输出：</p> <p>Translate the following question to SQL. “What is the age of a student called John Doe?” SELECT```</p> <p><img src="https://s2.loli.net/2025/04/15/zeQUIuGTSXa9VWB.webp" alt="select.webp"/></p> <p>Simple SQL grammar <img src="https://s2.loli.net/2025/04/15/SQ2cAoYObgtkKnp.webp" alt="grammar.webp"/></p> <p>a <a href="https://github.com/lark-parser/lark">lark</a> context free grammar definition:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">start</span><span class="p">:</span> <span class="n">select</span>
    <span class="n">select</span><span class="p">:</span> <span class="sh">"</span><span class="s">SELECT </span><span class="sh">"</span> <span class="n">columns</span> <span class="sh">"</span><span class="s">FROM </span><span class="sh">"</span> <span class="nf">table </span><span class="p">(</span><span class="sh">"</span><span class="s">WHERE </span><span class="sh">"</span> <span class="n">condition</span><span class="p">)</span><span class="err">?</span> <span class="sh">"</span><span class="s">;</span><span class="sh">"</span>   
 
    <span class="n">columns</span><span class="p">:</span> <span class="n">_columns</span> <span class="sh">"</span><span class="s"> </span><span class="sh">"</span>
    <span class="n">_columns</span><span class="p">:</span> <span class="nf">_column </span><span class="p">((</span><span class="sh">"</span><span class="s">,</span><span class="sh">"</span> <span class="o">|</span> <span class="sh">"</span><span class="s">, </span><span class="sh">"</span><span class="p">)</span> <span class="n">_column</span><span class="p">)</span><span class="o">*</span> <span class="o">|</span> <span class="sh">"</span><span class="s">*</span><span class="sh">"</span>
    <span class="n">_column</span><span class="p">:</span> <span class="o">/</span><span class="p">([</span><span class="n">A</span><span class="o">-</span><span class="n">Za</span><span class="o">-</span><span class="n">z0</span><span class="o">-</span><span class="mi">9</span><span class="p">]</span><span class="o">+</span><span class="p">)</span><span class="o">/</span>

    <span class="n">table</span><span class="p">:</span> <span class="n">_table</span> <span class="sh">"</span><span class="s"> </span><span class="sh">"</span>
    <span class="n">_table</span><span class="p">:</span> <span class="o">/</span><span class="p">[</span><span class="n">A</span><span class="o">-</span><span class="n">Za</span><span class="o">-</span><span class="n">z0</span><span class="o">-</span><span class="mi">9</span><span class="p">]</span><span class="o">+/</span>

    <span class="n">condition</span><span class="p">:</span> <span class="n">_first_term</span> <span class="n">_comp_op</span> <span class="n">_second_term</span>
    <span class="n">_comp_op</span><span class="p">:</span> <span class="sh">"</span><span class="s">=</span><span class="sh">"</span> <span class="o">|</span> <span class="sh">"</span><span class="s">!=</span><span class="sh">"</span> <span class="o">|</span> <span class="sh">"</span><span class="s">&lt;</span><span class="sh">"</span> <span class="o">|</span> <span class="sh">"</span><span class="s">&gt;</span><span class="sh">"</span> <span class="o">|</span> <span class="sh">"</span><span class="s">&lt;=</span><span class="sh">"</span> <span class="o">|</span> <span class="sh">"</span><span class="s">&gt;=</span><span class="sh">"</span>
    <span class="n">_first_term</span><span class="p">:</span> <span class="o">/</span><span class="p">([</span><span class="n">A</span><span class="o">-</span><span class="n">Za</span><span class="o">-</span><span class="n">z0</span><span class="o">-</span><span class="mi">9</span><span class="p">]</span><span class="o">+</span><span class="p">)</span> <span class="o">*/</span>
    <span class="n">_second_term</span><span class="p">:</span> <span class="o">/</span> <span class="o">*</span><span class="p">([</span><span class="n">A</span><span class="o">-</span><span class="n">Za</span><span class="o">-</span><span class="n">z0</span><span class="o">-</span><span class="mi">9</span><span class="p">]</span><span class="o">+|</span><span class="sh">'</span><span class="s">[^</span><span class="sh">'</span><span class="p">]</span><span class="o">*</span><span class="sh">'</span><span class="s">)/
</span></code></pre></div></div> <p>使用该语法生成SQL：</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pip</span> <span class="n">install</span> <span class="n">parserllm</span> <span class="n">transformers</span> <span class="n">lark</span>

<span class="kn">from</span> <span class="n">lark</span> <span class="kn">import</span> <span class="n">Lark</span>
<span class="kn">from</span> <span class="n">parserllm</span> <span class="kn">import</span> <span class="n">complete_cf</span>
<span class="kn">from</span> <span class="n">transfomers</span> <span class="kn">import</span> <span class="n">AutoModelForCausualLM</span><span class="p">,</span> <span class="n">AutoTOkenizer</span>

<span class="c1"># define our grammar
</span><span class="n">select_grammar</span> <span class="o">=</span> <span class="sh">"""</span><span class="s">
start: select
    select: </span><span class="sh">"</span><span class="s">SELECT </span><span class="sh">"</span><span class="s"> columns </span><span class="sh">"</span><span class="s">FROM </span><span class="sh">"</span><span class="s"> table (</span><span class="sh">"</span><span class="s">WHERE </span><span class="sh">"</span><span class="s"> condition)? </span><span class="sh">"</span><span class="s">;</span><span class="sh">"</span><span class="s">

    columns: _columns </span><span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="s">
    _columns: _column ((</span><span class="sh">"</span><span class="s">,</span><span class="sh">"</span><span class="s"> | </span><span class="sh">"</span><span class="s">, </span><span class="sh">"</span><span class="s">) _column)* | </span><span class="sh">"</span><span class="s">*</span><span class="sh">"</span><span class="s">
    _column: /([A-Za-z0-9]+)/

    table: _table </span><span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="s">
    _table: /[A-Za-z0-9]+/

    condition: _first_term _comp_op _second_term
    _comp_op: </span><span class="sh">"</span><span class="s">=</span><span class="sh">"</span><span class="s"> | </span><span class="sh">"</span><span class="s">!=</span><span class="sh">"</span><span class="s"> | </span><span class="sh">"</span><span class="s">&lt;</span><span class="sh">"</span><span class="s"> | </span><span class="sh">"</span><span class="s">&gt;</span><span class="sh">"</span><span class="s"> | </span><span class="sh">"</span><span class="s">&lt;=</span><span class="sh">"</span><span class="s"> | </span><span class="sh">"</span><span class="s">&gt;=</span><span class="sh">"</span><span class="s">
    _first_term: /([A-Za-z0-9]+) */
    _second_term: / *([A-Za-z0-9]+|</span><span class="sh">'</span><span class="s">[^</span><span class="sh">'</span><span class="s">]*</span><span class="sh">'</span><span class="s">)/
</span><span class="sh">"""</span>

<span class="c1"># create the parser - see lark docs for arguments
</span><span class="n">sql_parser</span> <span class="o">=</span> <span class="nc">Lark</span><span class="p">(</span><span class="n">grammar</span><span class="o">=</span><span class="n">select_grammar</span><span class="p">,</span> <span class="n">regex</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">parser</span><span class="o">=</span><span class="sh">'</span><span class="s">lalr</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># get the model and appropriate tokenizer
</span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="sh">"</span><span class="s">microsoft/phi-2</span><span class="sh">"</span><span class="p">,</span> <span class="n">trust_remote_code</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="sh">"</span><span class="s">microsoft/phi-2</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># define our prompt - this is a recommended format for phi-2
</span><span class="n">prompt</span> <span class="o">=</span> <span class="sh">"""</span><span class="s">Instruct: Can you translate the following question to SQL: </span><span class="se">\\</span><span class="sh">"</span><span class="s">What is the age of a student called </span><span class="sh">'</span><span class="s">John Doe</span><span class="sh">'</span><span class="s">?</span><span class="se">\\</span><span class="sh">"</span><span class="s">
Output:</span><span class="sh">"""</span>

<span class="c1"># generate a completion
</span><span class="n">completion</span> <span class="o">=</span> <span class="nf">complete_cf</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">sql_parser</span><span class="p">,</span> <span class="sh">""</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">25</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">completion</span><span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">SELECT</span> <span class="n">age</span> <span class="n">FROM</span> <span class="n">student</span> <span class="n">WHERE</span> <span class="n">name</span><span class="o">=</span> <span class="sh">'</span><span class="s">John Doe</span><span class="sh">'</span><span class="p">;</span>
</code></pre></div></div> <p>进一步地， 我们可以给语法添加表列信息：</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">start</span><span class="p">:</span> <span class="n">select</span>
    <span class="n">select</span><span class="p">:</span> <span class="sh">"</span><span class="s">SELECT </span><span class="sh">"</span> <span class="n">columns</span> <span class="sh">"</span><span class="s">FROM </span><span class="sh">"</span> <span class="nf">table </span><span class="p">(</span><span class="sh">"</span><span class="s">WHERE </span><span class="sh">"</span> <span class="n">condition</span><span class="p">)</span><span class="err">?</span> <span class="sh">"</span><span class="s">;</span><span class="sh">"</span>

    <span class="n">columns</span><span class="p">:</span> <span class="n">_columns</span> <span class="sh">"</span><span class="s"> </span><span class="sh">"</span>
    <span class="n">_columns</span><span class="p">:</span> <span class="nf">_column </span><span class="p">((</span><span class="sh">"</span><span class="s">,</span><span class="sh">"</span> <span class="o">|</span> <span class="sh">"</span><span class="s">, </span><span class="sh">"</span><span class="p">)</span> <span class="n">_column</span><span class="p">)</span><span class="o">*</span> <span class="o">|</span> <span class="sh">"</span><span class="s">*</span><span class="sh">"</span>
    <span class="n">_column</span><span class="p">:</span> <span class="sh">"</span><span class="s">zip_code</span><span class="sh">"</span> <span class="o">|</span> <span class="sh">"</span><span class="s">years_since_born</span><span class="sh">"</span> <span class="o">|</span> <span class="sh">"</span><span class="s">name</span><span class="sh">"</span> <span class="o">|</span> <span class="sh">"</span><span class="s">eye_color</span><span class="sh">"</span>

    <span class="n">table</span><span class="p">:</span> <span class="n">_table</span> <span class="sh">"</span><span class="s"> </span><span class="sh">"</span>
    <span class="n">_table</span><span class="p">:</span> <span class="o">/</span><span class="p">[</span><span class="n">A</span><span class="o">-</span><span class="n">Za</span><span class="o">-</span><span class="n">z0</span><span class="o">-</span><span class="mi">9</span><span class="p">]</span><span class="o">+/</span>

    <span class="n">condition</span><span class="p">:</span> <span class="n">_first_term</span> <span class="n">_comp_op</span> <span class="n">_second_term</span>
    <span class="n">_comp_op</span><span class="p">:</span> <span class="sh">"</span><span class="s">=</span><span class="sh">"</span> <span class="o">|</span> <span class="sh">"</span><span class="s">!=</span><span class="sh">"</span> <span class="o">|</span> <span class="sh">"</span><span class="s">&lt;</span><span class="sh">"</span> <span class="o">|</span> <span class="sh">"</span><span class="s">&gt;</span><span class="sh">"</span> <span class="o">|</span> <span class="sh">"</span><span class="s">&lt;=</span><span class="sh">"</span> <span class="o">|</span> <span class="sh">"</span><span class="s">&gt;=</span><span class="sh">"</span>
    <span class="n">_first_term</span><span class="p">:</span> <span class="o">/</span><span class="p">([</span><span class="n">A</span><span class="o">-</span><span class="n">Za</span><span class="o">-</span><span class="n">z0</span><span class="o">-</span><span class="mi">9</span><span class="p">]</span><span class="o">+</span><span class="p">)</span> <span class="o">*/</span>
    <span class="n">_second_term</span><span class="p">:</span> <span class="o">/</span> <span class="o">*</span><span class="p">([</span><span class="n">A</span><span class="o">-</span><span class="n">Za</span><span class="o">-</span><span class="n">z0</span><span class="o">-</span><span class="mi">9</span><span class="p">]</span><span class="o">+|</span><span class="sh">'</span><span class="s">[^</span><span class="sh">'</span><span class="p">]</span><span class="o">*</span><span class="sh">'</span><span class="s">)/
</span></code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">SELECT</span> <span class="n">name</span><span class="p">,</span><span class="n">years_since_born</span> <span class="n">FROM</span> <span class="n">student</span> <span class="n">WHERE</span> <span class="n">name</span><span class="o">=</span> <span class="sh">'</span><span class="s">John Doe</span><span class="sh">'</span><span class="p">;</span>
</code></pre></div></div> <h3 id="案例四-react状态信息与工具使用">案例四: ReAct状态信息与工具使用</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@guidance</span>
<span class="k">def</span> <span class="nf">react_prompt_example</span><span class="p">(</span><span class="n">lm</span><span class="p">,</span> <span class="n">question</span><span class="p">,</span> <span class="n">max_rounds</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">lm</span> <span class="o">+=</span> <span class="sa">f</span><span class="sh">'</span><span class="s">Question: </span><span class="si">{</span><span class="n">question</span><span class="si">}</span><span class="se">\n</span><span class="sh">'</span>
    <span class="n">i</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
        <span class="n">lm</span> <span class="o">+=</span> <span class="sa">f</span><span class="sh">'</span><span class="s">Thought </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s">: </span><span class="sh">'</span> <span class="o">+</span> <span class="nf">gen</span><span class="p">(</span><span class="n">suffix</span><span class="o">=</span><span class="sh">'</span><span class="se">\n</span><span class="sh">'</span><span class="p">)</span>
        <span class="n">lm</span> <span class="o">+=</span> <span class="sa">f</span><span class="sh">'</span><span class="s">Act </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s">: </span><span class="sh">'</span> <span class="o">+</span> <span class="nf">select</span><span class="p">([</span><span class="sh">'</span><span class="s">Search</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Finish</span><span class="sh">'</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">act</span><span class="sh">'</span><span class="p">)</span> 
        <span class="n">lm</span> <span class="o">+=</span> <span class="sh">'</span><span class="s">[</span><span class="sh">'</span> <span class="o">+</span> <span class="nf">gen</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">arg</span><span class="sh">'</span><span class="p">,</span> <span class="n">suffix</span><span class="o">=</span><span class="sh">'</span><span class="s">]</span><span class="sh">'</span><span class="p">)</span> <span class="o">+</span> <span class="sh">'</span><span class="se">\n</span><span class="sh">'</span>
        <span class="k">if</span> <span class="n">lm</span><span class="p">[</span><span class="sh">'</span><span class="s">act</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="sh">'</span><span class="s">Finish</span><span class="sh">'</span> <span class="ow">or</span> <span class="n">i</span> <span class="o">==</span> <span class="n">max_rounds</span><span class="p">:</span>
            <span class="k">break</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">lm</span> <span class="o">+=</span> <span class="sa">f</span><span class="sh">'</span><span class="s">Observation </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s">: </span><span class="sh">'</span> <span class="o">+</span> <span class="nf">search</span><span class="p">(</span><span class="n">lm</span><span class="p">[</span><span class="sh">'</span><span class="s">arg</span><span class="sh">'</span><span class="p">])</span> <span class="o">+</span> <span class="sh">'</span><span class="se">\n</span><span class="sh">'</span>
        <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">lm</span>
</code></pre></div></div> <p>优势：</p> <ul> <li>注入领域知识，模板和约束</li> <li>提升解码速度</li> </ul> <p>限制：</p> <p>需要获取logits</p> <p>自定义Logits</p> <h2 id="支持structured-output的开源大模型推理部署引擎">支持Structured output的开源大模型推理部署引擎</h2> <p>vLLM：支持outlines、xgrammar(in beta) SGLang：outlines, xgrammar</p> <p>支持的参数： guided_choice: the output will be exactly one of the choices.</p> <p>guided_regex: the output will follow the regex pattern.</p> <p>guided_json: the output will follow the JSON schema.</p> <p>guided_grammar: the output will follow the context free grammar.</p> <p>guided_whitespace_pattern: used to override the default whitespace pattern for guided json decoding.</p> <p>guided_decoding_backend: used to select the guided decoding backend to use.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from openai import OpenAI
client <span class="o">=</span> OpenAI<span class="o">(</span>
    <span class="nv">base_url</span><span class="o">=</span><span class="s2">"http://localhost:8000/v1"</span>,
    <span class="nv">api_key</span><span class="o">=</span><span class="s2">"-"</span>,
<span class="o">)</span>

completion <span class="o">=</span> client.chat.completions.create<span class="o">(</span>
    <span class="nv">model</span><span class="o">=</span><span class="s2">"Qwen/Qwen2.5-3B-Instruct"</span>,
    <span class="nv">messages</span><span class="o">=[</span>
        <span class="o">{</span><span class="s2">"role"</span>: <span class="s2">"user"</span>, <span class="s2">"content"</span>: <span class="s2">"Classify this sentiment: vLLM is wonderful!"</span><span class="o">}</span>
    <span class="o">]</span>,
    <span class="nv">extra_body</span><span class="o">={</span><span class="s2">"guided_choice"</span>: <span class="o">[</span><span class="s2">"positive"</span>, <span class="s2">"negative"</span><span class="o">]}</span>,
<span class="o">)</span>
print<span class="o">(</span>completion.choices[0].message.content<span class="o">)</span>
</code></pre></div></div> <h1 id="参考文献">参考文献</h1> <ol> <li><a href="https://arxiv.org/pdf/2404.07362v1">“We Need Structured Output”: Towards User-centered Constraintson Large Language Model Output</a></li> <li><a href="https://link.springer.com/article/10.1007/s11704-024-40555-y">Large language models for generative information extraction: a survey</a></li> <li><a href="https://openai.com/index/introducing-structured-outputs-in-the-api/">Introducing Structured Outputs in the API</a></li> <li><a href="https://arxiv.org/html/2402.06925v1">A Thorough Examination of Decoding Methods in the Era of LLMs</a></li> <li><a href="https://arxiv.org/pdf/2406.16838">From Decoding to Meta-Generation: Inference-time Algorithms for Large Language Models</a></li> <li><a href="https://arxiv.org/abs/2412.14352">A Survey on LLM Inference-Time Self-Improvement</a></li> <li><a href="https://github.com/Saibo-creator/Awesome-LLM-Constrained-Decoding">Awesome-LLM-Constrained-Decoding</a></li> <li><a href="https://arxiv.org/pdf/2307.09702">Efficient Guided Generation for Large Language Models</a></li> <li><a href="https://medium.com/shape-ai/syntax-strategies-generating-constrained-sql-with-llms-57afc97ec6f1">Syntax Strategies: generating constrained SQL with LLMs</a></li> <li><a href="https://blog.csdn.net/yjh_SE007/article/details/132259230">大语言模型控制生成的过程Trick：自定义LogitsProcessor实践</a></li> <li><a href="https://huggingface.co/docs/transformers/en/generation_strategies">Text generation strategies</a></li> <li><a href="https://blog.csdn.net/weixin_40498548/article/details/144938234?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-0-144938234-blog-123152252.235^v43^pc_blog_bottom_relevance_base2&amp;spm=1001.2101.3001.4242.1&amp;utm_relevant_index=3">LLM结构化输出代码示例和原理分析</a></li> <li><a href="https://blog.dottxt.co/say-what-you-mean.html">Say What You Mean: A Response to ‘Let Me Speak Freely’</a></li> <li><a href="https://arxiv.org/abs/2411.15100">XGrammar: Flexible and Efficient Structured Generation Engine for Large Language Models</a></li> </ol>]]></content><author><name></name></author><category term="insight"/><category term="llm"/><summary type="html"><![CDATA[Generating structured data from unstructured inputs is one of the core use cases for AI in today's applications.]]></summary></entry></feed>